{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05d8eb0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-12T22:30:54.566178Z",
     "iopub.status.busy": "2025-09-12T22:30:54.565855Z",
     "iopub.status.idle": "2025-09-12T22:30:56.263020Z",
     "shell.execute_reply": "2025-09-12T22:30:56.262079Z"
    },
    "papermill": {
     "duration": 1.702334,
     "end_time": "2025-09-12T22:30:56.264496",
     "exception": false,
     "start_time": "2025-09-12T22:30:54.562162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata yolu: /kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\n",
      "Satır x Sütun: (10015, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Görsel klasörleri:\n",
      "/kaggle/input/skin-cancer-mnist-ham10000/ham10000_images_part_1 -> True\n",
      "/kaggle/input/skin-cancer-mnist-ham10000/ham10000_images_part_2 -> True\n",
      "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1 -> True\n",
      "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2 -> True\n",
      "/kaggle/input/skin-cancer-mnist-ham10000/ham10000_images -> False\n",
      "/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images -> False\n",
      "\n",
      "Örnek görsel (varsa): /kaggle/input/skin-cancer-mnist-ham10000/ham10000_images_part_1/ISIC_0027419.jpg\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Kaggle'da eklediğin dataset yolu\n",
    "INPUT = Path(\"/kaggle/input/skin-cancer-mnist-ham10000\")\n",
    "\n",
    "# 1) Metadata oku ve ilk satırları göster\n",
    "meta_path = INPUT / \"HAM10000_metadata.csv\"\n",
    "df = pd.read_csv(meta_path)\n",
    "print(\"Metadata yolu:\", meta_path)\n",
    "print(\"Satır x Sütun:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# 2) Görsel klasörleri var mı kontrol et (isim varyantlarını da dene)\n",
    "candidates = [\n",
    "    INPUT/\"ham10000_images_part_1\",\n",
    "    INPUT/\"ham10000_images_part_2\",\n",
    "    INPUT/\"HAM10000_images_part_1\",\n",
    "    INPUT/\"HAM10000_images_part_2\",\n",
    "    INPUT/\"ham10000_images\",\n",
    "    INPUT/\"HAM10000_images\",\n",
    "]\n",
    "print(\"\\nGörsel klasörleri:\")\n",
    "for p in candidates:\n",
    "    print(p, \"->\", p.exists())\n",
    "\n",
    "# 3) Örnek bir görsel yolu oluştur (sadece kontrol)\n",
    "sample_file = df.loc[0, \"image_id\"] + \".jpg\"\n",
    "found = None\n",
    "for p in candidates:\n",
    "    if p.exists() and (p / sample_file).exists():\n",
    "        found = p / sample_file\n",
    "        break\n",
    "print(\"\\nÖrnek görsel (varsa):\", found)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa5878b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T22:30:56.271435Z",
     "iopub.status.busy": "2025-09-12T22:30:56.271003Z",
     "iopub.status.idle": "2025-09-12T22:33:50.423163Z",
     "shell.execute_reply": "2025-09-12T22:33:50.422399Z"
    },
    "papermill": {
     "duration": 174.15828,
     "end_time": "2025-09-12T22:33:50.426176",
     "exception": false,
     "start_time": "2025-09-12T22:30:56.267896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 7010 Val: 1502 Test: 1503\n",
      "Kopyalama tamam ✅ Eksik: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, shutil\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Yollar\n",
    "INPUT = Path(\"/kaggle/input/skin-cancer-mnist-ham10000\")\n",
    "PREP  = Path(\"/kaggle/working/data/prepared\")\n",
    "PREP.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(INPUT/\"HAM10000_metadata.csv\")\n",
    "df[\"filename\"] = df[\"image_id\"] + \".jpg\"\n",
    "\n",
    "# Split (%70 train, %15 val, %15 test)\n",
    "train_df, temp = train_test_split(df, test_size=0.3, stratify=df[\"dx\"], random_state=42)\n",
    "val_df, test_df = train_test_split(temp, test_size=0.5, stratify=temp[\"dx\"], random_state=42)\n",
    "\n",
    "df[\"split\"] = \"train\"\n",
    "df.loc[val_df.index,\"split\"]  = \"val\"\n",
    "df.loc[test_df.index,\"split\"] = \"test\"\n",
    "\n",
    "# metadata.csv kaydet\n",
    "df.to_csv(PREP/\"metadata.csv\", index=False)\n",
    "\n",
    "print(\"Train:\", len(train_df), \"Val:\", len(val_df), \"Test:\", len(test_df))\n",
    "\n",
    "# Klasörleri oluştur\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    for label in df[\"dx\"].unique():\n",
    "        (PREP/split/label).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Resimleri kopyala\n",
    "img_dirs = [\n",
    "    INPUT/\"ham10000_images_part_1\",\n",
    "    INPUT/\"ham10000_images_part_2\",\n",
    "]\n",
    "\n",
    "missing = 0\n",
    "for _, row in df.iterrows():\n",
    "    src = None\n",
    "    for d in img_dirs:\n",
    "        p = d/row[\"filename\"]\n",
    "        if p.exists():\n",
    "            src = p\n",
    "            break\n",
    "    if src is None:\n",
    "        missing += 1\n",
    "        continue\n",
    "    dst = PREP/row[\"split\"]/row[\"dx\"]/row[\"filename\"]\n",
    "    if not dst.exists():\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "print(\"Kopyalama tamam ✅ Eksik:\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a5f251",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T22:33:50.432399Z",
     "iopub.status.busy": "2025-09-12T22:33:50.431730Z",
     "iopub.status.idle": "2025-09-12T22:34:04.901593Z",
     "shell.execute_reply": "2025-09-12T22:34:04.900647Z"
    },
    "papermill": {
     "duration": 14.474662,
     "end_time": "2025-09-12T22:34:04.903198",
     "exception": false,
     "start_time": "2025-09-12T22:33:50.428536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-12 22:33:52.082589: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757716432.288052      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757716432.348215      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sınıflar: ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
      "Datasetler hazır ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757716444.706309      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1757716444.707002      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PREP = Path(\"/kaggle/working/data/prepared\")\n",
    "meta = pd.read_csv(PREP/\"metadata.csv\")\n",
    "\n",
    "IMG_SIZE = (224,224)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Basit text özelliği (örnek: \"sex:male localization:back age:45\")\n",
    "def build_text_feature(row):\n",
    "    return f\"sex:{row['sex']} localization:{row['localization']} age:{int(row['age']) if not pd.isna(row['age']) else -1}\"\n",
    "\n",
    "meta[\"text\"] = meta.apply(build_text_feature, axis=1)\n",
    "meta[\"filepath\"] = meta.apply(lambda r: str(PREP/r[\"split\"]/r[\"dx\"]/r[\"filename\"]), axis=1)\n",
    "\n",
    "# Sınıf isimleri\n",
    "class_names = sorted(meta[\"dx\"].unique())\n",
    "class_to_idx = {c:i for i,c in enumerate(class_names)}\n",
    "num_classes = len(class_names)\n",
    "\n",
    "meta[\"label\"] = meta[\"dx\"].map(class_to_idx)\n",
    "\n",
    "print(\"Sınıflar:\", class_names)\n",
    "\n",
    "# TensorFlow dataset hazırlama\n",
    "def decode_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    return tf.cast(img, tf.float32)/255.0\n",
    "\n",
    "def make_ds(df, training=True, batch_size=32):\n",
    "    paths = tf.convert_to_tensor(df[\"filepath\"].values)\n",
    "    texts = tf.convert_to_tensor(df[\"text\"].values)\n",
    "    labels = tf.one_hot(df[\"label\"].values, num_classes)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, texts, labels))\n",
    "\n",
    "    def _map(path, text, label):\n",
    "        img = decode_img(path)\n",
    "        if training:\n",
    "            img = tf.image.random_flip_left_right(img)\n",
    "        return ({\"image\": img, \"text\": text}, label)\n",
    "\n",
    "    if training:\n",
    "        ds = ds.shuffle(2048)\n",
    "    return ds.map(_map, num_parallel_calls=AUTOTUNE).batch(batch_size).prefetch(AUTOTUNE)\n",
    "\n",
    "train_ds = make_ds(meta[meta[\"split\"]==\"train\"])\n",
    "val_ds   = make_ds(meta[meta[\"split\"]==\"val\"], training=False)\n",
    "test_ds  = make_ds(meta[meta[\"split\"]==\"test\"], training=False)\n",
    "\n",
    "print(\"Datasetler hazır ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d01b4cc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T22:34:04.911084Z",
     "iopub.status.busy": "2025-09-12T22:34:04.910498Z",
     "iopub.status.idle": "2025-09-12T22:34:07.960726Z",
     "shell.execute_reply": "2025-09-12T22:34:07.959896Z"
    },
    "papermill": {
     "duration": 3.055548,
     "end_time": "2025-09-12T22:34:07.962058",
     "exception": false,
     "start_time": "2025-09-12T22:34:04.906510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ true_divide         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TrueDivide</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ text (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ true_divide[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ text_vectorization  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ text[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>) │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mobilenetv2_1.00_2… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │ subtract[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │ text_vectorizati… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ text_vectorizati… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mobilenetv2_1.00… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,920</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">360,704</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ image (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ true_divide         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mTrueDivide\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ text (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract (\u001b[38;5;33mSubtract\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ true_divide[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ text_vectorization  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ text[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m) │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mobilenetv2_1.00_2… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      │  \u001b[38;5;34m2,257,984\u001b[0m │ subtract[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m1280\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │    \u001b[38;5;34m256,000\u001b[0m │ text_vectorizati… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ text_vectorizati… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ mobilenetv2_1.00… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m49,920\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m360,704\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │      \u001b[38;5;34m1,799\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,926,407</span> (11.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,926,407\u001b[0m (11.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">668,423</span> (2.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m668,423\u001b[0m (2.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Text vectorizer adapte edildi ✅\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def build_fusion_model(num_classes, vocab_size=4000, seq_len=24, embed_dim=64):\n",
    "    # 🔹 Görsel taraf\n",
    "    img_in = tf.keras.Input(shape=(224,224,3), name=\"image\")\n",
    "    x = tf.keras.applications.mobilenet_v2.preprocess_input(img_in*255.0)\n",
    "    base = tf.keras.applications.MobileNetV2(\n",
    "        include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "    base.trainable = False  # önce dondur\n",
    "    x = base(x, training=False)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    # 🔹 Text taraf\n",
    "    txt_in = tf.keras.Input(shape=(), dtype=tf.string, name=\"text\")\n",
    "    vectorizer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=seq_len\n",
    "    )\n",
    "    # Adapt etmeyi unutma (train text ile yapacağız)\n",
    "    t = vectorizer(txt_in)\n",
    "    t = tf.keras.layers.Embedding(vocab_size, embed_dim, mask_zero=True)(t)\n",
    "    t = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64))(t)\n",
    "    t = tf.keras.layers.Dropout(0.2)(t)\n",
    "\n",
    "    # 🔹 Füzyon\n",
    "    z = tf.keras.layers.Concatenate()([x, t])\n",
    "    z = tf.keras.layers.Dense(256, activation=\"relu\")(z)\n",
    "    z = tf.keras.layers.Dropout(0.3)(z)\n",
    "    out = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(z)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[img_in, txt_in], outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model, vectorizer\n",
    "\n",
    "# Model oluştur\n",
    "model, text_vec = build_fusion_model(num_classes=len(class_names))\n",
    "print(model.summary())\n",
    "\n",
    "# TextVectorization adapt → train text ile\n",
    "train_texts = meta[meta[\"split\"]==\"train\"][\"text\"].astype(str).tolist()\n",
    "text_vec.adapt(tf.data.Dataset.from_tensor_slices(train_texts).batch(256))\n",
    "print(\"Text vectorizer adapte edildi ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d674372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T22:34:07.971124Z",
     "iopub.status.busy": "2025-09-12T22:34:07.970519Z",
     "iopub.status.idle": "2025-09-12T22:37:30.926252Z",
     "shell.execute_reply": "2025-09-12T22:37:30.925343Z"
    },
    "papermill": {
     "duration": 202.961497,
     "end_time": "2025-09-12T22:37:30.927718",
     "exception": false,
     "start_time": "2025-09-12T22:34:07.966221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 4.37305053025577, 1: 2.7817460317460316, 2: 1.3022478172023035, 3: 12.36331569664903, 4: 1.285530900421786, 5: 0.21338772031292808, 6: 10.115440115440116}\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757716457.885797      59 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3874 - loss: 2.4485\n",
      "Epoch 1: val_accuracy improved from -inf to 0.53728, saving model to /kaggle/working/best_model.keras\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.3879 - loss: 2.4440 - val_accuracy: 0.5373 - val_loss: 1.3360\n",
      "Epoch 2/10\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4983 - loss: 1.6045\n",
      "Epoch 2: val_accuracy improved from 0.53728 to 0.64048, saving model to /kaggle/working/best_model.keras\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 86ms/step - accuracy: 0.4993 - loss: 1.5996 - val_accuracy: 0.6405 - val_loss: 1.0197\n",
      "Epoch 3/10\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5651 - loss: 1.4045\n",
      "Epoch 3: val_accuracy did not improve from 0.64048\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 82ms/step - accuracy: 0.5658 - loss: 1.4005 - val_accuracy: 0.5866 - val_loss: 1.1406\n",
      "Epoch 4/10\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5693 - loss: 1.3552\n",
      "Epoch 4: val_accuracy improved from 0.64048 to 0.67177, saving model to /kaggle/working/best_model.keras\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.5702 - loss: 1.3511 - val_accuracy: 0.6718 - val_loss: 0.9603\n",
      "Epoch 5/10\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5985 - loss: 1.2510\n",
      "Epoch 5: val_accuracy did not improve from 0.67177\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 82ms/step - accuracy: 0.5993 - loss: 1.2472 - val_accuracy: 0.6698 - val_loss: 0.8803\n",
      "Epoch 6/10\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6245 - loss: 1.1924\n",
      "Epoch 6: val_accuracy did not improve from 0.67177\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 82ms/step - accuracy: 0.6251 - loss: 1.1890 - val_accuracy: 0.6505 - val_loss: 0.9957\n",
      "Epoch 7/10\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6414 - loss: 1.0966\n",
      "Epoch 7: val_accuracy improved from 0.67177 to 0.71438, saving model to /kaggle/working/best_model.keras\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 85ms/step - accuracy: 0.6420 - loss: 1.0937 - val_accuracy: 0.7144 - val_loss: 0.8311\n",
      "Epoch 8/10\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6494 - loss: 1.0817\n",
      "Epoch 8: val_accuracy did not improve from 0.71438\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 82ms/step - accuracy: 0.6501 - loss: 1.0782 - val_accuracy: 0.6578 - val_loss: 1.0144\n",
      "Epoch 9/10\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6442 - loss: 1.0647\n",
      "Epoch 9: val_accuracy did not improve from 0.71438\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 82ms/step - accuracy: 0.6447 - loss: 1.0617 - val_accuracy: 0.6684 - val_loss: 0.9489\n",
      "Epoch 10/10\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6423 - loss: 1.0643\n",
      "Epoch 10: val_accuracy did not improve from 0.71438\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 81ms/step - accuracy: 0.6429 - loss: 1.0612 - val_accuracy: 0.6791 - val_loss: 0.8768\n",
      "Test sonucu: [0.8499439358711243, 0.6959414482116699]\n"
     ]
    }
   ],
   "source": [
    "# Class imbalance için ağırlık hesapla\n",
    "from collections import Counter\n",
    "\n",
    "cnt = Counter(meta[meta[\"split\"]==\"train\"][\"dx\"])\n",
    "total = sum(cnt.values())\n",
    "class_weight = {class_to_idx[c]: total/(len(class_names)*cnt[c]) for c in class_names}\n",
    "print(\"Class weights:\", class_weight)\n",
    "\n",
    "# Callback'ler\n",
    "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"/kaggle/working/best_model.keras\", monitor=\"val_accuracy\", save_best_only=True, verbose=1\n",
    ")\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\", patience=3, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Eğitim\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[ckpt, es]\n",
    ")\n",
    "\n",
    "# Test sonucu\n",
    "print(\"Test sonucu:\", model.evaluate(test_ds, verbose=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e757e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T22:37:31.118860Z",
     "iopub.status.busy": "2025-09-12T22:37:31.118294Z",
     "iopub.status.idle": "2025-09-12T23:05:48.680463Z",
     "shell.execute_reply": "2025-09-12T23:05:48.679577Z"
    },
    "papermill": {
     "duration": 1697.658131,
     "end_time": "2025-09-12T23:05:48.681722",
     "exception": false,
     "start_time": "2025-09-12T22:37:31.023591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 4.37305053025577, 1: 2.7817460317460316, 2: 1.3022478172023035, 3: 12.36331569664903, 4: 1.285530900421786, 5: 0.21338772031292808, 6: 10.115440115440116}\n",
      "Epoch 1/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 258ms/step - accuracy: 0.5560 - loss: 1.3742 - val_accuracy: 0.6904 - val_loss: 0.8373 - learning_rate: 0.0010\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/model_checkpoint.py:209: UserWarning: Can save best model only with val_auc available, skipping.\n",
      "  self._save_model(epoch=epoch, batch=None, logs=logs)\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: accuracy,loss,val_accuracy,val_loss\n",
      "  current = self.get_monitor_value(logs)\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py:145: UserWarning: Learning rate reduction is conditioned on metric `val_auc` which is not available. Available metrics are: accuracy,loss,val_accuracy,val_loss,learning_rate.\n",
      "  callback.on_epoch_end(epoch, logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 257ms/step - accuracy: 0.5741 - loss: 1.2622 - val_accuracy: 0.6698 - val_loss: 0.9387 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.6025 - loss: 1.1825 - val_accuracy: 0.7144 - val_loss: 0.7765 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 257ms/step - accuracy: 0.6275 - loss: 1.0595 - val_accuracy: 0.6644 - val_loss: 0.9468 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 257ms/step - accuracy: 0.6288 - loss: 1.2119 - val_accuracy: 0.6558 - val_loss: 0.8986 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 257ms/step - accuracy: 0.6041 - loss: 1.1694 - val_accuracy: 0.6605 - val_loss: 0.9423 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 257ms/step - accuracy: 0.6295 - loss: 1.0976 - val_accuracy: 0.6611 - val_loss: 1.0392 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.6487 - loss: 1.1248 - val_accuracy: 0.6977 - val_loss: 0.7825 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.6507 - loss: 1.0598 - val_accuracy: 0.6551 - val_loss: 0.9520 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.6324 - loss: 1.0401 - val_accuracy: 0.6085 - val_loss: 1.0654 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.6614 - loss: 0.9861 - val_accuracy: 0.6991 - val_loss: 0.8080 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 257ms/step - accuracy: 0.6377 - loss: 1.0468 - val_accuracy: 0.6618 - val_loss: 0.9171 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.6402 - loss: 1.0171 - val_accuracy: 0.6485 - val_loss: 0.9927 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.6416 - loss: 1.0824 - val_accuracy: 0.6931 - val_loss: 0.8438 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.6689 - loss: 0.9757 - val_accuracy: 0.6951 - val_loss: 0.7866 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.6641 - loss: 0.9583 - val_accuracy: 0.6977 - val_loss: 0.8586 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.6827 - loss: 0.9392 - val_accuracy: 0.6971 - val_loss: 0.7955 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.6702 - loss: 0.9260 - val_accuracy: 0.7157 - val_loss: 0.8316 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.6756 - loss: 0.9783 - val_accuracy: 0.7104 - val_loss: 0.7598 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.6770 - loss: 0.9617 - val_accuracy: 0.6971 - val_loss: 0.8443 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 257ms/step - accuracy: 0.6656 - loss: 0.9530 - val_accuracy: 0.6658 - val_loss: 0.9526 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.6733 - loss: 0.9574 - val_accuracy: 0.7130 - val_loss: 0.7891 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.6771 - loss: 0.8788 - val_accuracy: 0.6924 - val_loss: 0.8529 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.7025 - loss: 0.9357 - val_accuracy: 0.7257 - val_loss: 0.7487 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.6781 - loss: 0.9184 - val_accuracy: 0.7037 - val_loss: 0.8398 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 254ms/step - accuracy: 0.6725 - loss: 0.9359 - val_accuracy: 0.7137 - val_loss: 0.7997 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.6614 - loss: 0.9154 - val_accuracy: 0.7230 - val_loss: 0.7563 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.7017 - loss: 0.8840 - val_accuracy: 0.7111 - val_loss: 0.7945 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 264ms/step - accuracy: 0.6948 - loss: 0.8007 - val_accuracy: 0.7330 - val_loss: 0.7305 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.6850 - loss: 0.8087 - val_accuracy: 0.7324 - val_loss: 0.7675 - learning_rate: 0.0010\n",
      "Test sonucu: [0.804090142250061, 0.7252162098884583]\n"
     ]
    }
   ],
   "source": [
    "# ✅ Class imbalance için ağırlıklar\n",
    "from collections import Counter\n",
    "cnt = Counter(meta[meta[\"split\"]==\"train\"][\"dx\"])\n",
    "total = sum(cnt.values())\n",
    "class_weight = {class_to_idx[c]: total/(len(class_names)*cnt[c]) for c in class_names}\n",
    "print(\"Class weights:\", class_weight)\n",
    "\n",
    "# ✅ Data augmentation (görseller için)\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "# Dataset pipeline’ını augmentation ile güncelle\n",
    "def make_ds(df, training=True, batch_size=32):\n",
    "    paths = tf.convert_to_tensor(df[\"filepath\"].values)\n",
    "    texts = tf.convert_to_tensor(df[\"text\"].values)\n",
    "    labels = tf.one_hot(df[\"label\"].values, num_classes)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, texts, labels))\n",
    "\n",
    "    def _map(path, text, label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.io.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img = tf.cast(img, tf.float32)/255.0\n",
    "        if training:\n",
    "            img = data_augmentation(img)\n",
    "        return ({\"image\": img, \"text\": text}, label)\n",
    "\n",
    "    if training:\n",
    "        ds = ds.shuffle(2048)\n",
    "    return ds.map(_map, num_parallel_calls=AUTOTUNE).batch(batch_size).prefetch(AUTOTUNE)\n",
    "\n",
    "train_ds = make_ds(meta[meta[\"split\"]==\"train\"])\n",
    "val_ds   = make_ds(meta[meta[\"split\"]==\"val\"], training=False)\n",
    "test_ds  = make_ds(meta[meta[\"split\"]==\"test\"], training=False)\n",
    "\n",
    "# ✅ Callback'ler\n",
    "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"/kaggle/working/best_model.keras\", monitor=\"val_auc\", mode=\"max\",\n",
    "    save_best_only=True, verbose=1\n",
    ")\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_auc\", mode=\"max\",\n",
    "    patience=5, restore_best_weights=True\n",
    ")\n",
    "lr_sched = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_auc\", mode=\"max\",\n",
    "    factor=0.5, patience=2, verbose=1, min_lr=1e-7\n",
    ")\n",
    "\n",
    "# ✅ Eğitim\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30,   # daha uzun tut, early stopping ile durur\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[ckpt, es, lr_sched]\n",
    ")\n",
    "\n",
    "# ✅ Test sonucu\n",
    "print(\"Test sonucu:\", model.evaluate(test_ds, verbose=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9094b53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T23:05:49.427223Z",
     "iopub.status.busy": "2025-09-12T23:05:49.426702Z",
     "iopub.status.idle": "2025-09-12T23:05:49.878758Z",
     "shell.execute_reply": "2025-09-12T23:05:49.877953Z"
    },
    "papermill": {
     "duration": 0.82325,
     "end_time": "2025-09-12T23:05:49.879942",
     "exception": false,
     "start_time": "2025-09-12T23:05:49.056692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mevcut model kaydedildi ✅ /kaggle/working/ham10000_model_v1.keras\n"
     ]
    }
   ],
   "source": [
    "# ✅ Mevcut modeli kaydet\n",
    "model.save(\"/kaggle/working/ham10000_model_v1.keras\")\n",
    "\n",
    "print(\"Mevcut model kaydedildi ✅ /kaggle/working/ham10000_model_v1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8884a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T23:05:50.678711Z",
     "iopub.status.busy": "2025-09-12T23:05:50.677979Z",
     "iopub.status.idle": "2025-09-12T23:22:04.097597Z",
     "shell.execute_reply": "2025-09-12T23:22:04.096707Z"
    },
    "papermill": {
     "duration": 973.794862,
     "end_time": "2025-09-12T23:22:04.098902",
     "exception": false,
     "start_time": "2025-09-12T23:05:50.304040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.7161 - auc: 0.9522 - loss: 0.8717\n",
      "Epoch 1: val_auc improved from -inf to 0.95730, saving model to /kaggle/working/best_model_auc.keras\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 262ms/step - accuracy: 0.7166 - auc: 0.9523 - loss: 0.8693 - val_accuracy: 0.7510 - val_auc: 0.9573 - val_loss: 0.7408 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.7269 - auc: 0.9559 - loss: 0.8122\n",
      "Epoch 2: val_auc did not improve from 0.95730\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.7273 - auc: 0.9560 - loss: 0.8099 - val_accuracy: 0.7397 - val_auc: 0.9544 - val_loss: 0.7604 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.7299 - auc: 0.9558 - loss: 0.7979\n",
      "Epoch 3: val_auc did not improve from 0.95730\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.7303 - auc: 0.9559 - loss: 0.7955 - val_accuracy: 0.7130 - val_auc: 0.9493 - val_loss: 0.7978 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.7032 - auc: 0.9506 - loss: 0.8410\n",
      "Epoch 4: val_auc did not improve from 0.95730\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.7035 - auc: 0.9507 - loss: 0.8384 - val_accuracy: 0.7277 - val_auc: 0.9534 - val_loss: 0.7823 - learning_rate: 5.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.7256 - auc: 0.9565 - loss: 0.8110\n",
      "Epoch 5: val_auc did not improve from 0.95730\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.7259 - auc: 0.9566 - loss: 0.8085 - val_accuracy: 0.7523 - val_auc: 0.9569 - val_loss: 0.7426 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.6903 - auc: 0.9489 - loss: 0.9216\n",
      "Epoch 6: val_auc improved from 0.95730 to 0.95795, saving model to /kaggle/working/best_model_auc.keras\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 258ms/step - accuracy: 0.6907 - auc: 0.9490 - loss: 0.9187 - val_accuracy: 0.7443 - val_auc: 0.9579 - val_loss: 0.7223 - learning_rate: 2.5000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.7401 - auc: 0.9629 - loss: 0.7348\n",
      "Epoch 7: val_auc did not improve from 0.95795\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.7402 - auc: 0.9629 - loss: 0.7331 - val_accuracy: 0.7344 - val_auc: 0.9566 - val_loss: 0.7308 - learning_rate: 2.5000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.7461 - auc: 0.9632 - loss: 0.7047\n",
      "Epoch 8: val_auc did not improve from 0.95795\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 254ms/step - accuracy: 0.7462 - auc: 0.9633 - loss: 0.7030 - val_accuracy: 0.7377 - val_auc: 0.9574 - val_loss: 0.7300 - learning_rate: 2.5000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.7392 - auc: 0.9610 - loss: 0.7748\n",
      "Epoch 9: val_auc improved from 0.95795 to 0.95952, saving model to /kaggle/working/best_model_auc.keras\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 259ms/step - accuracy: 0.7393 - auc: 0.9610 - loss: 0.7726 - val_accuracy: 0.7417 - val_auc: 0.9595 - val_loss: 0.7073 - learning_rate: 1.2500e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.7546 - auc: 0.9669 - loss: 0.7108\n",
      "Epoch 10: val_auc did not improve from 0.95952\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 256ms/step - accuracy: 0.7546 - auc: 0.9669 - loss: 0.7090 - val_accuracy: 0.7403 - val_auc: 0.9584 - val_loss: 0.7151 - learning_rate: 1.2500e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.7643 - auc: 0.9692 - loss: 0.6549\n",
      "Epoch 11: val_auc did not improve from 0.95952\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.7642 - auc: 0.9691 - loss: 0.6536 - val_accuracy: 0.7403 - val_auc: 0.9588 - val_loss: 0.7131 - learning_rate: 1.2500e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.7665 - auc: 0.9690 - loss: 0.7230\n",
      "Epoch 12: val_auc improved from 0.95952 to 0.95961, saving model to /kaggle/working/best_model_auc.keras\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 258ms/step - accuracy: 0.7665 - auc: 0.9690 - loss: 0.7210 - val_accuracy: 0.7330 - val_auc: 0.9596 - val_loss: 0.7100 - learning_rate: 6.2500e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.7669 - auc: 0.9700 - loss: 0.6622\n",
      "Epoch 13: val_auc did not improve from 0.95961\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.7668 - auc: 0.9699 - loss: 0.6607 - val_accuracy: 0.7264 - val_auc: 0.9581 - val_loss: 0.7199 - learning_rate: 6.2500e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.7730 - auc: 0.9694 - loss: 0.6955\n",
      "Epoch 14: val_auc did not improve from 0.95961\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.7729 - auc: 0.9693 - loss: 0.6938 - val_accuracy: 0.7197 - val_auc: 0.9563 - val_loss: 0.7350 - learning_rate: 3.1250e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.7730 - auc: 0.9703 - loss: 0.6577\n",
      "Epoch 15: val_auc did not improve from 0.95961\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.7728 - auc: 0.9703 - loss: 0.6564 - val_accuracy: 0.7210 - val_auc: 0.9565 - val_loss: 0.7351 - learning_rate: 3.1250e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.7750 - auc: 0.9701 - loss: 0.6519\n",
      "Epoch 16: val_auc did not improve from 0.95961\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.7748 - auc: 0.9700 - loss: 0.6505 - val_accuracy: 0.7217 - val_auc: 0.9559 - val_loss: 0.7397 - learning_rate: 1.5625e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m219/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.7839 - auc: 0.9717 - loss: 0.6492\n",
      "Epoch 17: val_auc did not improve from 0.95961\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 255ms/step - accuracy: 0.7837 - auc: 0.9717 - loss: 0.6478 - val_accuracy: 0.7204 - val_auc: 0.9556 - val_loss: 0.7408 - learning_rate: 1.5625e-05\n",
      "Test sonucu: [0.7421141862869263, 0.7445109486579895, 0.9555637836456299]\n"
     ]
    }
   ],
   "source": [
    "# 🚀 Yeni deneme: val_auc metrikli\n",
    "from tensorflow import keras\n",
    "\n",
    "# Tekrar compile (AUC dahil)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\", keras.metrics.AUC(name=\"auc\")]\n",
    ")\n",
    "\n",
    "# Class weights hesaplamıştık zaten -> class_weight değişkenini kullan\n",
    "# Yeni callback'ler\n",
    "ckpt = keras.callbacks.ModelCheckpoint(\n",
    "    \"/kaggle/working/best_model_auc.keras\",\n",
    "    monitor=\"val_auc\", save_best_only=True, mode=\"max\", verbose=1\n",
    ")\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_auc\", patience=5, restore_best_weights=True, mode=\"max\"\n",
    ")\n",
    "rlr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_auc\", factor=0.5, patience=2, verbose=1, mode=\"max\"\n",
    ")\n",
    "\n",
    "# Eğitim\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,   # uzun eğitim için daha fazla epoch\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[ckpt, es, rlr]\n",
    ")\n",
    "\n",
    "# Test sonucu\n",
    "print(\"Test sonucu:\", model.evaluate(test_ds, verbose=0))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 54339,
     "sourceId": 104884,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3078.185059,
   "end_time": "2025-09-12T23:22:08.477666",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-12T22:30:50.292607",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
